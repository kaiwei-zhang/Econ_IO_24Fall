{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d58033d",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Problem 1](#toc1_)    \n",
    "  - [1(a)](#toc1_1_)    \n",
    "  - [1(a)-2](#toc1_2_)    \n",
    "  - [1(b)](#toc1_3_)    \n",
    "  - [1(c)](#toc1_4_)    \n",
    "  - [1(d)](#toc1_5_)    \n",
    "  - [1(e)](#toc1_6_)    \n",
    "  - [Compare estimations from different methods](#toc1_7_)    \n",
    "- [Problem 2](#toc2_)    \n",
    "  - [2(a)](#toc2_1_)    \n",
    "  - [2(b)](#toc2_2_)    \n",
    "  - [2(c)](#toc2_3_)    \n",
    "  - [2(d)](#toc2_4_)    \n",
    "  - [2(e)](#toc2_5_)    \n",
    "- [3: use nested logit demand and FOC..](#toc3_)    \n",
    "  - [3(a)](#toc3_1_)    \n",
    "  - [3(a)-1: check fully competition context](#toc3_2_)    \n",
    "  - [3(b): a merge between 1 and 2](#toc3_3_)    \n",
    "  - [3(d): when all firms are colluding](#toc3_4_)    \n",
    "    - [3(d)-1: Direct maximize profit](#toc3_4_1_)    \n",
    "    - [3(d)-2 use FOC to solve Nash](#toc3_4_2_)    \n",
    "- [4: redo 3 with MultiNomial Logit](#toc4_)    \n",
    "  - [3(a)](#toc4_1_)    \n",
    "  - [3(b)](#toc4_2_)    \n",
    "  - [3(c) and 3(d)](#toc4_3_)    \n",
    "    - [Answer for 3(c):](#toc4_3_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c03f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_homework1 import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "global demand_df, c_jt_dic, PARAMS, alpha, Temp_t, data, params_IV, nest_params_IV\n",
    "global p_jt_dic, s_jt_dic, s_jmidgt_dic, s_gt_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebda824",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Problem 1: MNL demand](#toc0_)\n",
    "## <a id='toc1_1_'></a>[1(a) Run OLS for MNL](#toc0_)\n",
    "In this part I reg $ln(s_{jt}/s_{0t})$ to $X_{jt},p_{jt}$, no constant. This means I treat $\\xi_j$ as noise in regression with mean 0. In 1(b) I take them as constants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               log_odds   R-squared:                       0.885\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.884\n",
      "Method:                     Two Stage   F-statistic:                       nan\n",
      "                        Least Squares   Prob (F-statistic):                nan\n",
      "Date:                Sat, 21 Sep 2024                                         \n",
      "Time:                        21:38:10                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     995                                         \n",
      "Df Model:                           4                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "price         -1.6261      0.021    -77.352      0.000      -1.667      -1.585\n",
      "sugar          1.5281      0.041     37.444      0.000       1.448       1.608\n",
      "caffeine       1.4458      0.029     50.517      0.000       1.390       1.502\n",
      "Diet          -2.4406      0.149    -16.422      0.000      -2.732      -2.149\n",
      "Regular       -6.6921      0.245    -27.269      0.000      -7.174      -6.211\n",
      "==============================================================================\n",
      "Omnibus:                        1.109   Durbin-Watson:                   1.901\n",
      "Prob(Omnibus):                  0.574   Jarque-Bera (JB):                1.172\n",
      "Skew:                          -0.048   Prob(JB):                        0.557\n",
      "Kurtosis:                       2.862   Cond. No.                         63.3\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "Dic_para_q1 = dict()\n",
    "Dic_para_q2q3 = dict()\n",
    "# Load the data\n",
    "data = pd.read_csv('product_data.csv')\n",
    "data = prepare_data(data)\n",
    "\n",
    "# Prepare the design matrix X and dependent variable y\n",
    "# X = data[['price', 'sugar', 'caffeine', 'Diet', 'Regular']]\n",
    "# y = data['log_odds']\n",
    "\n",
    "# # Fit the model\n",
    "# model = sm.OLS(y, X)\n",
    "# model_results = model.fit()\n",
    "\n",
    "model_results = run_2sls(data,['log_odds'],['price', 'sugar', 'caffeine', 'Diet', 'Regular'],[],[])\n",
    "\n",
    "# Print the results\n",
    "print(model_results.summary())\n",
    "\n",
    "params_ols = get_parameters(model_results, nested=False, print_results=False)\n",
    "Dic_para_q1['OLS'] = params_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd627e07",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[1(a)-2: Run another OLS, adding j-specific time-invariant constants as j-firm specific shocks. No significant change in estimations.](#toc0_)\n",
    "In this part I reg $ln(s_{jt}/s_{0t})$ to $X_{jt},p_{jt}$, no constant and 9 dummies for each j (drop ID_1). This means I treat $\\xi_j$ as fixed within periods in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d28028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_dummies = pd.get_dummies(data['product_ID'], prefix='ID').astype(int)\n",
    "# ID_dummies = ID_dummies.drop('ID_1', axis=1)\n",
    "\n",
    "# X = pd.concat([X, ID_dummies], axis=1)\n",
    "# y = data['log_odds']\n",
    "\n",
    "# # Fit the model\n",
    "# model = sm.OLS(y, X)\n",
    "# model_results = model.fit()\n",
    "\n",
    "# # Print the results\n",
    "# params_ols_fixed_effect = get_parameters(\n",
    "#     model_results, nested=False, print_results=True)\n",
    "# Dic_para_q1['OLS_fixed_effect'] = params_ols_fixed_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4dbceb",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[1(b): Now use IV for price. Simplity using ingredients prices. ](#toc0_)\n",
    "The main concern of endogeneity is that $P_j$ is affected by $\\xi_j$, say brand effect.\n",
    "\n",
    "So use price for ingredients: sugar and caffine price.\n",
    "\n",
    "They are valid IV, since firm j's ingredients' price certainly affect price via cost, but they have little relationship with firm j's brand effect. (using other firms' ingredients price are not valid since they are not related with firm j's price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203f04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha (price): -1.4104\n",
      "beta1 (sugar): 1.4277\n",
      "beta2 (caffeine): 1.3821\n",
      "gamma_D (Diet): -2.5573\n",
      "gamma_R (Regular): -6.6182\n"
     ]
    }
   ],
   "source": [
    "iv_results = run_2sls(data,['log_odds'],['price', 'sugar', 'caffeine', 'Diet', 'Regular'],['caffeine_extract_price','corn_syrup_price'],['price'])\n",
    "\n",
    "# Print the results\n",
    "params_IV = get_parameters(iv_results, nested=False, print_results=True)\n",
    "Dic_para_q1['IV'] = params_IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb10ad",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[1(c): Calculate own price derivative and own price elasticity](#toc0_)\n",
    "Let $M=\\sum_{k\\neq j} exp(\\delta_k)+1$, then $\\frac{\\partial s_{jt}}{\\partial p_{jt}}=\\frac{Mexp(\\delta_{jt})}{(M+exp(\\delta_{jt}))^2}\\alpha=\\alpha s_{jt}(1-s_{jt})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f6cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean own-price elasticity for Regular drinks: -4.2011\n",
      "Mean own-price elasticity for Diet drinks: -2.9747\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate own-price derivative\n",
    "def own_price_derivative(alpha, s_jt):\n",
    "    return alpha * s_jt * (1 - s_jt)\n",
    "\n",
    "# Function to calculate own-price elasticity\n",
    "def own_price_elasticity(alpha, p_jt, s_jt):\n",
    "    return alpha * p_jt * (1 - s_jt)\n",
    "\n",
    "# Given df and params, calculate the own-price derivative and elasticity, Under any MNL setting\n",
    "# return mean elasticity for Regular and Diet drinks, and modified df\n",
    "def own_PD_PE(df, params):\n",
    "    \"\"\"take alpha and call the function, return the results\"\"\"\n",
    "    data = df.copy()\n",
    "    # Calculate own-price derivatives and elasticities\n",
    "    alpha = params['alpha']\n",
    "    data['own_price_derivative'] = own_price_derivative(\n",
    "        alpha, data['market_share'])\n",
    "    data['own_price_elasticity'] = own_price_elasticity(\n",
    "        alpha, data['price'], data['market_share'])\n",
    "\n",
    "    # Calculate mean elasticities for Regular and Diet drinks\n",
    "    mean_elasticity_regular = data[data['nest']\n",
    "                                   == 'Regular']['own_price_elasticity'].mean()\n",
    "    mean_elasticity_diet = data[data['nest'] ==\n",
    "                                'Diet']['own_price_elasticity'].mean()\n",
    "\n",
    "    print(\n",
    "        f\"Mean own-price elasticity for Regular drinks: {mean_elasticity_regular:.4f}\")\n",
    "    print(\n",
    "        f\"Mean own-price elasticity for Diet drinks: {mean_elasticity_diet:.4f}\")\n",
    "\n",
    "    return [mean_elasticity_regular, mean_elasticity_diet, data]\n",
    "\n",
    "\n",
    "[mean_elasticity_regular, mean_elasticity_diet,\n",
    "    data] = own_PD_PE(data, params_IV)\n",
    "Dic_para_q2q3['own_elasticity_regular_1c'] = mean_elasticity_regular\n",
    "Dic_para_q2q3['own_elasticity_diet_1c'] = mean_elasticity_diet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9f682",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[1(d): Calculate cross price derivatives and elasiticity with product 1](#toc0_)\n",
    "Similarly $\\frac{\\partial s_{jt}}{\\partial p_{1t}}=-\\alpha s_{jt}s_{1t}$\n",
    "Compared to 1(c), cross price derivatives are positive, (own should be certainly negative). Also I expect under MNL setting, cross price elasiticity within group is larger. However here I get wrong directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6960ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-price elasticity between product 1 and Diet sodas: 0.2054\n",
      "Mean cross-price elasticity between product 1 and Regular sodas: 0.3867\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate cross-price derivative\n",
    "def cross_price_derivative(alpha, s_jt, s_it):\n",
    "    return -alpha * s_jt * s_it\n",
    "\n",
    "# Function to calculate cross-price elasticity\n",
    "def cross_price_elasticity(alpha, p_1t, s_jt, s_1t):\n",
    "    return -alpha * p_1t * s_jt\n",
    "\n",
    "# Given df and params, calculate the cross-price derivative and elasticity with product 1, Under any MNL setting. return mean elasticity for Regular and Diet drinks, and modified df\n",
    "def cross_PD_PE(df, params):\n",
    "    data = df.copy()\n",
    "    alpha = params['alpha']\n",
    "\n",
    "    # Get product 1's market share for each time period\n",
    "    product_1_share = data[data['product_ID'] == 1].set_index('t')[\n",
    "        'market_share']\n",
    "\n",
    "    # Calculate cross-price derivatives and elasticities\n",
    "    data['cross_price_derivative'] = data.apply(lambda row: cross_price_derivative(alpha, row['market_share'], product_1_share[row['t']])\n",
    "                                                if row['product_ID'] != 1 else np.nan, axis=1)\n",
    "\n",
    "    data['cross_price_elasticity'] = data.apply(lambda row: cross_price_elasticity(alpha, data.loc[(data['product_ID'] == 1) & (data['t'] == row['t']), 'price'].values[0],\n",
    "                                                row['market_share'], product_1_share[row['t']])\n",
    "                                                if row['product_ID'] != 1 else np.nan, axis=1)\n",
    "\n",
    "    # Calculate mean cross-price elasticities\n",
    "    mean_cross_elasticity_diet = data[(data['nest'] == 'Diet') & (\n",
    "        data['product_ID'] != 1)]['cross_price_elasticity'].mean()\n",
    "    mean_cross_elasticity_regular = data[(data['nest'] == 'Regular') & (\n",
    "        data['product_ID'] != 1)]['cross_price_elasticity'].mean()\n",
    "\n",
    "    print(\n",
    "        f\"Mean cross-price elasticity between product 1 and Diet sodas: {mean_cross_elasticity_diet:.4f}\")\n",
    "    print(\n",
    "        f\"Mean cross-price elasticity between product 1 and Regular sodas: {mean_cross_elasticity_regular:.4f}\")\n",
    "    return [mean_cross_elasticity_diet, mean_cross_elasticity_regular, data]\n",
    "\n",
    "\n",
    "[mean_cross_elasticity_diet, mean_cross_elasticity_regular,\n",
    "    data] = cross_PD_PE(data, params_IV)\n",
    "Dic_para_q2q3['cross_elasticity_regular_1d'] = mean_cross_elasticity_regular\n",
    "Dic_para_q2q3['cross_elasticity_diet_1d'] = mean_cross_elasticity_diet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f25215",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[1(e):generate Jacobian](#toc0_)\n",
    "Use the formula that $\\frac{\\partial s_{jt}}{\\partial p_{it}}=-\\alpha s_{jt}s_{it}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17a9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian matrix for period 100:\n",
      "[[-0.083  0.     0.001  0.002  0.022  0.003  0.039  0.009  0.004  0.003]\n",
      " [ 0.    -0.002  0.     0.     0.     0.     0.001  0.     0.     0.   ]\n",
      " [ 0.001  0.    -0.014  0.     0.004  0.001  0.006  0.001  0.001  0.001]\n",
      " [ 0.002  0.     0.    -0.028  0.007  0.001  0.013  0.003  0.001  0.001]\n",
      " [ 0.022  0.     0.004  0.007 -0.261  0.014  0.154  0.033  0.014  0.012]\n",
      " [ 0.003  0.     0.001  0.001  0.014 -0.053  0.025  0.005  0.002  0.002]\n",
      " [ 0.039  0.001  0.006  0.013  0.154  0.025 -0.348  0.06   0.026  0.023]\n",
      " [ 0.009  0.     0.001  0.003  0.033  0.005  0.06  -0.123  0.006  0.005]\n",
      " [ 0.004  0.     0.001  0.001  0.014  0.002  0.026  0.006 -0.055  0.002]\n",
      " [ 0.003  0.     0.001  0.001  0.012  0.002  0.023  0.005  0.002 -0.049]]\n"
     ]
    }
   ],
   "source": [
    "def generate_jacobian(time_period, data, params):\n",
    "    \"\"\"\n",
    "    Generate the Jacobian matrix of price derivatives for a given time period.\n",
    "    I Do need market_share column in the data pd\n",
    "    Returns: np.array like Jacobian matrix of price derivatives.\n",
    "    \"\"\"\n",
    "    alpha = params['alpha']\n",
    "    # Filter data for the given time period\n",
    "    period_data = data[data['t'] == time_period]\n",
    "    n_products = len(period_data)\n",
    "    shares = period_data['market_share'].values\n",
    "\n",
    "    # Initialize the Jacobian matrix\n",
    "    jacobian = np.zeros((n_products, n_products))\n",
    "\n",
    "    # Fill in the Jacobian matrix\n",
    "    for i in range(n_products):\n",
    "        for j in range(n_products):\n",
    "            if i == j:\n",
    "                # Own-price derivative\n",
    "                s_it = shares[i]\n",
    "                jacobian[i, i] = own_price_derivative(alpha, s_it)\n",
    "            else:\n",
    "                # Cross-price derivative\n",
    "                s_jt = shares[j]\n",
    "                s_it = shares[i]\n",
    "                jacobian[i, j] = cross_price_derivative(alpha, s_jt,  s_it)\n",
    "\n",
    "    return jacobian\n",
    "\n",
    "\n",
    "def print_jacobian(data, params_IV):\n",
    "    # Generate Jacobian for the last time period\n",
    "    last_period = data['t'].max()\n",
    "    jacobian_last_period = generate_jacobian(last_period, data, params_IV)\n",
    "    print(f\"Jacobian matrix for period {last_period}:\")\n",
    "    print(np.round(jacobian_last_period, 3))\n",
    "\n",
    "\n",
    "data_Q1 = data.copy()\n",
    "print_jacobian(data, params_IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3d285",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Compare estimations from different methods](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108f5340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>-1.626102</td>\n",
       "      <td>-1.410449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta1</th>\n",
       "      <td>1.528062</td>\n",
       "      <td>1.427685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2</th>\n",
       "      <td>1.445800</td>\n",
       "      <td>1.382064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_D</th>\n",
       "      <td>-2.440599</td>\n",
       "      <td>-2.557333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_R</th>\n",
       "      <td>-6.692118</td>\n",
       "      <td>-6.618158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OLS        IV\n",
       "alpha   -1.626102 -1.410449\n",
       "beta1    1.528062  1.427685\n",
       "beta2    1.445800  1.382064\n",
       "gamma_D -2.440599 -2.557333\n",
       "gamma_R -6.692118 -6.618158"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Dic_para_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8c79b",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Problem 2: Nested Logit Demand](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c489fc",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2(a) (OLS)IV for Nested logit demand estimation](#toc0_)\n",
    "If we use OLS I need to estimate \n",
    "$$log(odd share_{jt}) = \\alpha* price_{jt}+\\beta_1* sugar_{jt}+\\beta_2 *caffine_{jt}+\\gamma_D*Diet_{jt}+\\gamma_R*Regular_{jt}+\\sigma log(s_{jt \\mid g})+\\xi_{jt}$$\n",
    "\n",
    "Now If I'm considering IV, clearly both price and log_within_share is endogenous since they are both affected by brand effects.\n",
    "\n",
    "- For price, I can still use ingredients price as IV, like before.\n",
    "\n",
    "- For log_within_share, I create new IV $caffine_{-j,t\\mid g},sugar_{-j,t\\mid g}$:\n",
    "\n",
    "    - other firms' (within group) sugar and caffine level affects their competition, so affects firm j's within group share\n",
    "\n",
    "    - other firms' sugar and caffine level has nothing to do with firm j's brand effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067b1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dic_para_q2 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43a2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log_within_share\n",
    "data['group_share'] = data.groupby(\n",
    "    ['t', 'nest'])['market_share'].transform('sum')\n",
    "data['within_group_share'] = data['market_share'] / data['group_share']\n",
    "data['log_within_share'] = np.log(data['within_group_share'])\n",
    "\n",
    "# Create sugar_mean_within_group: other products' average sugar content within the same nest\n",
    "# So I generate sum of sugar content for each nest, and then subtract the sugar content of the product itself\n",
    "# then divide by the number of other products in the nest\n",
    "data['others_sugar_mean_within_group'] = data.groupby( ['t', 'nest'])['sugar'].transform('sum') - data['sugar']\n",
    "data['others_sugar_mean_within_group'] = data['others_sugar_mean_within_group'] / 4\n",
    "\n",
    "# Create caffeine_mean_within_group: other products' average caffeine content within the same nest\n",
    "data['others_caffeine_mean_within_group'] = data.groupby( ['t', 'nest'])['caffeine'].transform('sum') - data['caffeine']\n",
    "data['others_caffeine_mean_within_group'] = data['others_caffeine_mean_within_group'] / 4\n",
    "\n",
    "# Prepare the exogenous, endogenous, and instrumental variables: form lists\n",
    "exog_list = ['sugar', 'caffeine', 'Diet', 'Regular']\n",
    "endog_list = ['price','log_within_share']\n",
    "IV_list = ['caffeine_extract_price','corn_syrup_price', 'others_sugar_mean_within_group', 'others_caffeine_mean_within_group']\n",
    "\n",
    "# Perfpoem OLS estimation\n",
    "ols_model_results = run_2sls(data,['log_odds'],exog_list+endog_list,[],[])\n",
    "nest_params_ols = get_parameters(\n",
    "    ols_model_results, nested=True, print_results=False)\n",
    "Dic_para_q2['nest_OLS'] = nest_params_ols\n",
    "\n",
    "# Perform 2SLS estimation\n",
    "iv_model_results = run_2sls(data,['log_odds'],exog_list+endog_list,IV_list,endog_list)\n",
    "nest_params_IV = get_parameters(\n",
    "    ols_model_results, nested=True, print_results=False)\n",
    "Dic_para_q2['nest_params_IV'] = nest_params_IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fcd677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': -0.2532813843353505,\n",
       " 'beta1': 0.27041110296014864,\n",
       " 'beta2': 0.2929096026449775,\n",
       " 'gamma_D': 2.9749030721821303,\n",
       " 'gamma_R': 2.7206717244795784,\n",
       " 'sigma': 0.852208191222261}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_params_IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b8f13",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[2(b): calculate price elasiticy and derivatives under Nested Logit Setting](#toc0_)\n",
    "\n",
    "Under nested logit it's a little bit hard to calculate..\n",
    "\n",
    "The formulas are:\n",
    "\n",
    "$$\\partial s_{j}/\\partial p_{j}= \\alpha/(1-\\sigma)s_j(1-s_{j|g})+\\alpha s_j(1-s_g)s_{j|g} $$\n",
    "\n",
    "and if $k\\neq j, k\\in J_j$:\n",
    "$$\\partial s_{j}/\\partial p_{k}= -\\alpha/(1-\\sigma)s_j(1-s_{k|g})-\\alpha s_k(1-s_g)s_{j|g} $$\n",
    "\n",
    "and if $k\\neq j, k\\notin J_j$:\n",
    "$$\\partial s_{j}/\\partial p_{k}= -\\alpha s_{j}s_{k} $$\n",
    "\n",
    "So I need diction/functions that given j,t: get p_jt, s_jt, s_j|g, s_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4a6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dictionaries for me to check price,s_j,s_jmidg,s_g, given (j,t)\n",
    "p_jt_dic = dict(data.set_index(['product_ID', 't'])['price'])\n",
    "s_jt_dic = dict(data.set_index(['product_ID', 't'])['market_share'])\n",
    "s_jmidgt_dic = dict(data.set_index(['product_ID', 't'])['within_group_share'])\n",
    "s_gt_dic = dict(data.set_index(['product_ID', 't'])['group_share'])\n",
    "\n",
    "# check whether j and k are in the same nest\n",
    "def Bool_same_group(j, k):\n",
    "    if j <= 5 and k <= 5:\n",
    "        return True\n",
    "    if j >= 6 and k >= 6:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# own price derivative and elasticity, under nest setting\n",
    "def own_price_derivative_nest(alpha, sigma, j, t, s_jt_dic=s_jt_dic, s_gt_dic=s_gt_dic, s_jmidgt_dic=s_jmidgt_dic):\n",
    "    s_j = s_jt_dic[(j, t)]\n",
    "    s_g = s_gt_dic[(j, t)]\n",
    "    s_jmidg = s_jmidgt_dic[(j, t)]\n",
    "    return alpha/(1-sigma)*s_j*(1-s_jmidg)+alpha*s_j*(1-s_g)*s_jmidg\n",
    "\n",
    "def own_price_elasticity_nest(alpha, sigma, j, t, s_jt_dic=s_jt_dic, s_gt_dic=s_gt_dic, s_jmidgt_dic=s_jmidgt_dic):\n",
    "    s_j = s_jt_dic[(j, t)]\n",
    "    p_j = s_jt_dic[(j, t)]\n",
    "    A = own_price_derivative_nest(alpha, sigma, j, t)\n",
    "    return A*p_j/s_j\n",
    "\n",
    "# cross price derivative and elasticity, under nest setting. I generalize the function to include the case when j=k: just return own price derivative and elasticity\n",
    "def cross_price_derivative_nest(alpha, sigma, j, k, t, s_jt_dic=s_jt_dic, s_gt_dic=s_gt_dic, s_jmidgt_dic=s_jmidgt_dic):\n",
    "    if j == k:\n",
    "        return own_price_derivative_nest(alpha, sigma, j, t, s_jt_dic=s_jt_dic, s_gt_dic=s_gt_dic, s_jmidgt_dic=s_jmidgt_dic)\n",
    "    s_j = s_jt_dic[(j, t)]\n",
    "    s_g = s_gt_dic[(j, t)]\n",
    "    s_k = s_jt_dic[(k, t)]\n",
    "    s_jmidg = s_jmidgt_dic[(j, t)]\n",
    "    s_kmidg = s_jmidgt_dic[(k, t)]\n",
    "    if Bool_same_group(j, k):  # long\n",
    "        a = -alpha/(1-sigma)*s_j*(1-s_kmidg)\n",
    "        b = -alpha*s_k*(1-s_g)*s_jmidg\n",
    "        return a+b\n",
    "    else:\n",
    "        return -alpha*s_j*s_k\n",
    "\n",
    "\n",
    "def cross_price_elasticity_nest(alpha, sigma, j, k, t):\n",
    "    if j == k:\n",
    "        return own_price_elasticity_nest(alpha, sigma, j, t)\n",
    "    s_j = s_jt_dic[(j, t)]\n",
    "    p_k = s_jt_dic[(k, t)]\n",
    "    A = cross_price_derivative_nest(alpha, sigma, j, k, t)\n",
    "    return A*p_k/s_j\n",
    "\n",
    "# generate a list of T jacobbians. Each jacobbians is a dictionary with key being (j,k) and value being the derivative or elasticity\n",
    "def complex_matrix_calculation(alpha, sigma, f, g):\n",
    "    results = [{} for _ in range(100)]\n",
    "    # go throgh t,j,k\n",
    "    for t in range(1, 101):\n",
    "        for j in range(1, 11):\n",
    "            for k in range(1, 11):\n",
    "                if j != k:\n",
    "                    value = f(alpha, sigma, j, k, t)\n",
    "                    results[t-1][(j-1, k-1)] = value\n",
    "                else:\n",
    "                    results[t-1][(j-1, k-1)] = g(alpha, sigma, j, t)\n",
    "    return results\n",
    "\n",
    "\n",
    "alpha = nest_params_IV['alpha']\n",
    "sigma = nest_params_IV['sigma']\n",
    "\n",
    "# generate own price derivative and elasticity in data\n",
    "# generate cross price derivative and elasticity, and jacobbians in Jaccobians list of jacobian matrix\n",
    "data['own_price_derivative_nest'] = data.apply(lambda row: own_price_derivative_nest(\n",
    "    alpha, sigma, row['product_ID'], row['t']), axis=1)\n",
    "\n",
    "data['own_price_elasticity_nest'] = data.apply(lambda row: own_price_elasticity_nest(\n",
    "    alpha, sigma, row['product_ID'], row['t']), axis=1)\n",
    "\n",
    "Jacobbians = complex_matrix_calculation(\n",
    "    alpha, sigma, cross_price_derivative_nest, own_price_derivative_nest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ecf29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-price elasticity between product 1 and Diet sodas: -0.0790\n",
      "Mean cross-price elasticity between product 1 and Regular sodas: -0.1406\n"
     ]
    }
   ],
   "source": [
    "# print desired results for 2(b)\n",
    "mean_own_elasticity_diet_nest = data[(\n",
    "    data['nest'] == 'Diet')]['own_price_derivative_nest'].mean()\n",
    "mean_own_elasticity_regular_nest = data[(\n",
    "    data['nest'] == 'Regular')]['own_price_derivative_nest'].mean()\n",
    "\n",
    "print(\n",
    "    f\"Mean cross-price elasticity between product 1 and Diet sodas: {mean_own_elasticity_diet_nest:.4f}\")\n",
    "print(\n",
    "    f\"Mean cross-price elasticity between product 1 and Regular sodas: {mean_own_elasticity_regular_nest:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c170a20",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[2(c): Just call function for cross price elasiticities and derivatives with 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c570af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-price elasticity between product 1 and Diet sodas: 0.0708\n",
      "Mean cross-price elasticity between product 1 and Regular sodas: 0.0022\n"
     ]
    }
   ],
   "source": [
    "data['cross_price_derivative_nest'] = data.apply(lambda row: cross_price_derivative_nest(\n",
    "    alpha, sigma, row['product_ID'], 1, row['t']), axis=1)\n",
    "\n",
    "data['cross_price_elasticity_nest'] = data.apply(lambda row: cross_price_elasticity_nest(\n",
    "    alpha, sigma, row['product_ID'], 1, row['t']), axis=1)\n",
    "\n",
    "mean_cross_elasticity_diet_nest = data[(data['nest'] == 'Diet') & (\n",
    "    data['product_ID'] != 1)]['cross_price_elasticity_nest'].mean()\n",
    "mean_cross_elasticity_regular_nest = data[(data['nest'] == 'Regular') & (\n",
    "    data['product_ID'] != 1)]['cross_price_elasticity_nest'].mean()\n",
    "\n",
    "print(\n",
    "    f\"Mean cross-price elasticity between product 1 and Diet sodas: {mean_cross_elasticity_diet_nest:.4f}\")\n",
    "print(\n",
    "    f\"Mean cross-price elasticity between product 1 and Regular sodas: {mean_cross_elasticity_regular_nest:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7132bf",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[2(d)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eacbb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IV</th>\n",
       "      <th>nest_params_IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>-1.410</td>\n",
       "      <td>-0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta1</th>\n",
       "      <td>1.428</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2</th>\n",
       "      <td>1.382</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_D</th>\n",
       "      <td>-2.557</td>\n",
       "      <td>2.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_R</th>\n",
       "      <td>-6.618</td>\n",
       "      <td>2.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IV  nest_params_IV\n",
       "alpha   -1.410          -0.253\n",
       "beta1    1.428           0.270\n",
       "beta2    1.382           0.293\n",
       "gamma_D -2.557           2.975\n",
       "gamma_R -6.618           2.721\n",
       "sigma      NaN           0.852"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_2 = pd.DataFrame(Dic_para_q2)\n",
    "part_1 = pd.DataFrame(Dic_para_q1)\n",
    "merge_params_all = pd.concat([part_1, part_2], axis=1)\n",
    "wanted_lis = [x for x in merge_params_all.columns if 'IV' in x]\n",
    "merge_params_all[wanted_lis].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be41d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>own_elasticity_regular_1c</th>\n",
       "      <td>-4.201058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>own_elasticity_diet_1c</th>\n",
       "      <td>-2.974664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_elasticity_regular_1d</th>\n",
       "      <td>0.386651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_elasticity_diet_1d</th>\n",
       "      <td>0.205371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "own_elasticity_regular_1c   -4.201058\n",
       "own_elasticity_diet_1c      -2.974664\n",
       "cross_elasticity_regular_1d  0.386651\n",
       "cross_elasticity_diet_1d     0.205371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([Dic_para_q2q3]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4ec6b",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[2(e):Just call last jacobbian and print](#toc0_)\n",
    "\n",
    "Can observe that this jacobbian is more nested than MNL one: members (j,k) where $j<5<k$ or $j>5>k$ are almost 0. And within group elasiticty is larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a813e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09  0.11  0.1   0.1   0.02  0.    0.01  0.    0.    0.  ]\n",
      " [ 0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.01  0.02 -0.02  0.02  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.03  0.03  0.03 -0.03  0.01  0.    0.    0.    0.    0.  ]\n",
      " [ 0.33  0.42  0.41  0.39 -0.15  0.    0.03  0.01  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.06  0.02  0.06  0.06  0.06]\n",
      " [ 0.01  0.    0.    0.    0.03  0.71 -0.27  0.64  0.71  0.72]\n",
      " [ 0.    0.    0.    0.    0.01  0.15  0.05 -0.14  0.15  0.16]\n",
      " [ 0.    0.    0.    0.    0.    0.07  0.02  0.06 -0.07  0.07]\n",
      " [ 0.    0.    0.    0.    0.    0.06  0.02  0.05  0.06 -0.06]]\n"
     ]
    }
   ],
   "source": [
    "double_index_dic = Jacobbians[-1]\n",
    "\n",
    "# prepare the jacobian matrix for print\n",
    "def construct_jacobbian(dic):\n",
    "    jacobian = np.zeros((10, 10))\n",
    "\n",
    "    # Fill in the Jacobian matrix\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            jacobian[i, j] = dic[(i, j)]\n",
    "    return jacobian\n",
    "\n",
    "\n",
    "print(np.round(construct_jacobbian(double_index_dic), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119012e",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[3: use nested logit demand and FOC..](#toc0_)\n",
    "The big picture here is that I need a functional form which takes a input of price, give me share and derivaties. So I can use them for GMM/minimizing loss.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "235e38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for demand/share under NestLogit setting, not for T=100 specifically\n",
    "def share_function_NestLogit_old(temp_price):\n",
    "    global demand_df, c_jt_dic, PARAMS, alpha, Temp_t, data\n",
    "    \"\"\"This is a mapping: given params&demand_df(I need sugar,caffeine, Diet,Regular),\n",
    "    period t, and len-10 vector price, generate expected market share which is also len-10 vector\"\"\"\n",
    "    [alpha, beta1, beta2, gammaD, gammaR, sigma] = list(\n",
    "        nest_params_IV.values())\n",
    "    temp_t = Temp_t\n",
    "    temp_demand_df = demand_df[demand_df['t'] == temp_t]\n",
    "    # M stands for delta-alpha*price\n",
    "    temp_demand_df['M'] = temp_demand_df['sugar']*beta1+temp_demand_df['caffeine'] * \\\n",
    "        beta2+temp_demand_df['Diet']*gammaD+temp_demand_df['Regular']*gammaR\n",
    "    temp_demand_df['Price'] = temp_price  # use temp_price as given price input\n",
    "\n",
    "    temp_demand_df['middle'] = temp_demand_df['Price']*alpha\n",
    "\n",
    "    temp_demand_df['delta'] = temp_demand_df['middle']+temp_demand_df['M']\n",
    "    temp_demand_df['delta_over_1minussigma'] = temp_demand_df['delta'] / \\\n",
    "        (1-sigma)\n",
    "    temp_demand_df['exp_delt_sigma'] = np.exp(\n",
    "        temp_demand_df['delta_over_1minussigma'])\n",
    "\n",
    "    nest_sums = temp_demand_df.groupby(\n",
    "        'Diet')['exp_delt_sigma'].transform('sum')\n",
    "    temp_demand_df['share_in_nest'] = temp_demand_df['exp_delt_sigma'] / nest_sums\n",
    "\n",
    "    temp_G = temp_demand_df.groupby(['Diet']).agg({'exp_delt_sigma': sum})\n",
    "    G_lis = list(temp_G['exp_delt_sigma'])\n",
    "    D_diet = G_lis[0]\n",
    "    D_regular = G_lis[1]\n",
    "    s_diet = D_diet**(1-sigma)\n",
    "    s_regular = D_regular**(1-sigma)  # s for D_g**(1-sigma)\n",
    "    s_diet, s_regular\n",
    "    denom = s_diet+s_regular+1\n",
    "    D_gdiet = s_diet/denom\n",
    "    D_gregular = s_regular/denom\n",
    "    \n",
    "    # Now we get D_g for each group\n",
    "    temp_demand_df['sum_group'] = 0\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 1, 'sum_group'] = D_diet\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 0, 'sum_group'] = D_regular\n",
    "    temp_demand_df['s_jt_given_g'] = temp_demand_df['exp_delt_sigma'] / \\\n",
    "        temp_demand_df['sum_group']\n",
    "\n",
    "    temp_demand_df['s_g'] = 0\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 1, 's_g'] = D_gdiet\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 0, 's_g'] = D_gregular\n",
    "\n",
    "    temp_demand_df['s_jt'] = temp_demand_df['share_in_nest'] * \\\n",
    "        temp_demand_df['s_g']\n",
    "\n",
    "    temp_demand_df = temp_demand_df.sort_index()\n",
    "    # to make sure the sort is correct so I can check j's expected share by [j-1]\n",
    "    return list(temp_demand_df['s_jt'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d27d1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not needed\n",
    "# and generate \\hat xi_{jt}\n",
    "global demand_df, c_jt_dic, PARAMS, alpha, Temp_t, data\n",
    "Temp_t=100\n",
    "[alpha, beta1, beta2, gammaD, gammaR, sigma] = list(\n",
    "    nest_params_IV.values())\n",
    "\n",
    "want_lis = ['product_ID', 'nest', 'price', 'sugar', 'caffeine', 'market_share',\n",
    "       'caffeine_extract_price', 'corn_syrup_price', 't', 'outside_share',\n",
    "       'log_odds', 'Diet', 'Regular', 'group_share', 'within_group_share']\n",
    "data = data[want_lis]\n",
    "data\n",
    "\n",
    "data['M'] = data['sugar']*beta1+data['caffeine'] * \\\n",
    "    beta2+data['Diet']*gammaD+data['Regular']*gammaR+data['price']*alpha\n",
    "\n",
    "data['xi_hat'] = data['log_odds']-data['M']\n",
    "\n",
    "data=data.drop(['M'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a1c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def share_function_NestLogit(temp_price):\n",
    "    temp_t = Temp_t\n",
    "    temp_demand_df = data[data['t'] == temp_t]\n",
    "    # M stands for delta-alpha*price\n",
    "    temp_demand_df['M'] = temp_demand_df['sugar']*beta1+temp_demand_df['caffeine'] * \\\n",
    "        beta2+temp_demand_df['Diet']*gammaD+temp_demand_df['Regular']*gammaR\n",
    "    temp_demand_df['Price'] = temp_price  # use temp_price as given price input\n",
    "\n",
    "    temp_demand_df['middle'] = temp_demand_df['Price']*alpha\n",
    "\n",
    "    # should include xi_hat or not?\n",
    "    temp_demand_df['delta'] = temp_demand_df['middle']+temp_demand_df['M']+temp_demand_df['xi_hat']\n",
    "    temp_demand_df['delta_over_1minussigma'] = temp_demand_df['delta'] / \\\n",
    "        (1-sigma)\n",
    "\n",
    "    temp_demand_df['exp_delt_over_1minussigma'] = np.exp(\n",
    "        temp_demand_df['delta_over_1minussigma'])\n",
    "\n",
    "    nest_sums = temp_demand_df.groupby(\n",
    "        'Diet')['exp_delt_over_1minussigma'].transform('sum')\n",
    "    temp_demand_df['share_in_nest'] = temp_demand_df['exp_delt_over_1minussigma'] / nest_sums\n",
    "    temp_demand_df\n",
    "\n",
    "    temp_G =temp_demand_df.groupby(['nest']).agg({'exp_delt_over_1minussigma': sum})\n",
    "\n",
    "    G_lis = list(temp_G['exp_delt_over_1minussigma'])\n",
    "    D_diet = G_lis[0]  # D_g for sum_{j\\in g} exp(delta_j/(1-sigma))\n",
    "    D_regular = G_lis[1]\n",
    "    s_diet = D_diet**(1-sigma)\n",
    "    s_regular = D_regular**(1-sigma)  # s for D_g**(1-sigma)\n",
    "    s_diet, s_regular\n",
    "    denom = s_diet+s_regular+1  # 1 for outside group\n",
    "    group_demand_diet = s_diet/denom\n",
    "    group_demand_regular = s_regular/denom\n",
    "    # Now we get D_g for each group: s_g\n",
    "    temp_demand_df['group_demand'] = 0\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 1, 'group_demand'] = group_demand_diet\n",
    "    temp_demand_df.loc[temp_demand_df['Diet'] == 0, 'group_demand'] = group_demand_regular\n",
    "\n",
    "    temp_demand_df['market_share_expect'] = temp_demand_df['share_in_nest'] * \\\n",
    "        temp_demand_df['group_demand']\n",
    "\n",
    "    temp_demand_df.columns\n",
    "    unwanted_lis=['M','middle','delta','delta_over_1minussigma','exp_delt_over_1minussigma']\n",
    "    temp_demand_df=temp_demand_df.drop(unwanted_lis,axis=1)\n",
    "\n",
    "    temp_demand_df = temp_demand_df.sort_index()\n",
    "    # to make sure the sort is correct so I can check j's expected share by [j-1]\n",
    "    return list(temp_demand_df['market_share_expect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d06e2e",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[3(a): Estimating constant costs](#toc0_)\n",
    "Given derivatives from Nested logit, their FOC should be \n",
    "$$p_j+(\\alpha/(1-\\sigma)(1-s_{j\\mid g})+\\alpha(1-s_g)s_{j\\mid g})^{-1}=c_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b40c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lerner_nest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.365666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.253106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.217576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.235777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.232576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lerner_nest\n",
       "product_ID             \n",
       "1              0.358178\n",
       "2              0.344418\n",
       "3              0.340845\n",
       "4              0.362416\n",
       "5              0.365666\n",
       "6              0.232206\n",
       "7              0.253106\n",
       "8              0.217576\n",
       "9              0.235777\n",
       "10             0.232576"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate c_{jt} matrix\n",
    "def calc_cost_Nest(alpha, sigma, j, t):\n",
    "    s_j = s_jt_dic[(j, t)]\n",
    "    s_g = s_gt_dic[(j, t)]\n",
    "    s_jmidg = s_jmidgt_dic[(j, t)]\n",
    "    p_j = p_jt_dic[(j, t)]\n",
    "    a = alpha/(1-sigma)*(1-s_jmidg)+alpha*(1-s_g)*s_jmidg\n",
    "    return p_j+1/a\n",
    "\n",
    "\n",
    "data['cost_nest'] = data.apply(lambda row: calc_cost_Nest(\n",
    "    alpha, sigma, row['product_ID'], row['t']), axis=1)\n",
    "\n",
    "# use cost to estimate Lerner\n",
    "data['middle_2'] = data['price']-data['cost_nest']\n",
    "data['Lerner_nest'] = data['middle_2']/data['price']\n",
    "data.groupby('product_ID').agg({'Lerner_nest': np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d6ece3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_ID', 'nest', 'price', 'sugar', 'caffeine', 'market_share',\n",
       "       'caffeine_extract_price', 'corn_syrup_price', 't', 'outside_share',\n",
       "       'log_odds', 'Diet', 'Regular', 'group_share', 'within_group_share',\n",
       "       'xi_hat', 'cost_nest', 'middle_2', 'Lerner_nest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89374bc",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[3(a)-1: check fully competition context](#toc0_)\n",
    "I first check the fully competition context. Under this setting FOC for each firm is\n",
    "$$s_j+(p_j-c_j)\\partial s_j/\\partial p_j=0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "706815cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some global variables to pin down t=100 data\n",
    "global subdf,c_j_dic1\n",
    "subdf = data.query('t==100').reset_index().drop('index', axis=1)\n",
    "subdf = subdf[['product_ID', 'nest', 'sugar',\n",
    "               'caffeine', 'cost_nest', 't', 'Diet', 'Regular']]\n",
    "demand_df = subdf\n",
    "temp_price = list(data[data['t'] == 100]['price'])\n",
    "Temp_t = 100\n",
    "\n",
    "# given j and k, and price in R^10, return partial s_j/partial p_k(p)\n",
    "# since I take global subdf, I can only use it for T=100 specifically\n",
    "def d_sj_pk(j, k, temp_price):\n",
    "    \"\"\"A function given j and k, and price in R^10, return partial s_j/partial p_k(p)\"\"\"\n",
    "    share_lis = share_function_NestLogit(temp_price)\n",
    "    subdf['price'] = temp_price\n",
    "    subdf['market_share'] = share_lis\n",
    "\n",
    "    subdf['group_share'] = subdf.groupby(\n",
    "        ['nest'])['market_share'].transform('sum')\n",
    "    subdf['within_group_share'] = subdf['market_share'] / subdf['group_share']\n",
    "\n",
    "    # each time a new temp_price is generated, s_j dic will be updated\n",
    "    p_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['price'])\n",
    "    s_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['market_share'])\n",
    "    s_jmidg_dic1 = dict(subdf.set_index(\n",
    "        ['product_ID', 't'])['within_group_share'])\n",
    "    s_g_dic1 = dict(subdf.set_index(['product_ID', 't'])['group_share'])\n",
    "    c_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['cost_nest'])\n",
    "\n",
    "    return cross_price_derivative_nest(alpha, sigma, j, k, t=100, s_jt_dic=s_j_dic1, s_gt_dic=s_g_dic1, s_jmidgt_dic=s_jmidg_dic1)\n",
    "\n",
    "# given p, return share, share_within_grooup and group share. aalso return cost dic for simplicity\n",
    "# also only for t=100 specifically\n",
    "def other_items(temp_price):\n",
    "    share_lis = share_function_NestLogit(temp_price)\n",
    "    subdf['price'] = temp_price\n",
    "    subdf['market_share'] = share_lis\n",
    "    subdf['group_share'] = subdf.groupby(\n",
    "        ['nest'])['market_share'].transform('sum')\n",
    "    subdf['within_group_share'] = subdf['market_share'] / subdf['group_share']\n",
    "\n",
    "    p_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['price'])\n",
    "    s_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['market_share'])\n",
    "    s_jmidg_dic1 = dict(subdf.set_index(\n",
    "        ['product_ID', 't'])['within_group_share'])\n",
    "    s_g_dic1 = dict(subdf.set_index(['product_ID', 't'])['group_share'])\n",
    "    c_j_dic1 = dict(subdf.set_index(['product_ID', 't'])['cost_nest'])\n",
    "\n",
    "    return [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8609e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss for abs(diff:FOC) under full competitions\n",
    "def loss_nest_competition(price):\n",
    "    [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(price)\n",
    "    loss = 0\n",
    "    for j in range(1, 11):\n",
    "        s_j = s_j_dic1[(j, Temp_t)]\n",
    "        c_j = c_j_dic1[(j, Temp_t)]\n",
    "        c_j = c_j_dic1[(j, Temp_t)]\n",
    "        p_j = price[j-1]\n",
    "        a = s_j+(p_j-c_j)*d_sj_pk(j, j, price)\n",
    "        loss += abs(a)\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = minimize(loss_nest_competition, temp_price,\n",
    "                  tol=1e-5, method='Nelder-Mead')\n",
    "price_full_competition = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aff0293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: Optimization terminated successfully.\n",
       "       success: True\n",
       "        status: 0\n",
       "           fun: 0.023149158066077154\n",
       "             x: [ 3.082e+00  1.376e+00  7.642e-01  1.362e+00  5.665e+00\n",
       "                  3.813e+00  9.378e+00  3.922e+00  2.498e+00  1.677e+00]\n",
       "           nit: 476\n",
       "          nfev: 759\n",
       " final_simplex: (array([[ 3.082e+00,  1.376e+00, ...,  2.498e+00,\n",
       "                         1.677e+00],\n",
       "                       [ 3.082e+00,  1.376e+00, ...,  2.498e+00,\n",
       "                         1.677e+00],\n",
       "                       ...,\n",
       "                       [ 3.082e+00,  1.376e+00, ...,  2.498e+00,\n",
       "                         1.677e+00],\n",
       "                       [ 3.082e+00,  1.376e+00, ...,  2.498e+00,\n",
       "                         1.677e+00]]), array([ 2.315e-02,  2.315e-02,  2.315e-02,  2.315e-02,\n",
       "                        2.315e-02,  2.315e-02,  2.315e-02,  2.315e-02,\n",
       "                        2.315e-02,  2.315e-02,  2.315e-02]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c6830",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[3(b): a merge between 1 and 2](#toc0_)\n",
    "Now FOC for each firm is\n",
    "$$s_1+(p_1-c_1)\\partial s_1/\\partial p_1+(p_2-c_2)\\partial s_2/\\partial p_1=0$$\n",
    "\n",
    "$$s_2+(p_1-c_1)\\partial s_1/\\partial p_2+(p_1-c_1)\\partial s_1/\\partial p_2=0$$\n",
    "\n",
    "$$s_j+(p_j-c_j)\\partial s_j/\\partial p_j=0, \\forall j\\ge 3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97d9d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss for abs(diff:FOC) under the case when 1 and 2 are merging\n",
    "def loss_merge_1and2(price):\n",
    "    [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(price)\n",
    "    loss = 0\n",
    "    for j in range(3, 11):\n",
    "        s_j = s_j_dic1[(j, Temp_t)]\n",
    "        c_j = c_j_dic1[(j, Temp_t)]\n",
    "        p_j = price[j-1]\n",
    "        a = s_j+(p_j-c_j)*d_sj_pk(j, j, price)\n",
    "        loss += abs(a)\n",
    "    s1 = s_j_dic1[(1, Temp_t)]\n",
    "    p1 = price[0]\n",
    "    c1 = c_j_dic1[(1, Temp_t)]\n",
    "    s2 = s_j_dic1[(2, Temp_t)]\n",
    "    p2 = price[1]\n",
    "    c2 = c_j_dic1[(2, Temp_t)]\n",
    "    ds2p1 = d_sj_pk(2, 1, price)\n",
    "    ds1p2 = d_sj_pk(1, 2, price)\n",
    "    ds1p1 = d_sj_pk(1, 1, price)\n",
    "    ds2p2 = d_sj_pk(2, 2, price)\n",
    "    a = s1+(p1-c1)*ds1p1+(p2-c2)*ds2p1\n",
    "    loss += abs(a)\n",
    "    a = s2+(p2-c2)*ds2p2+(p1-c1)*ds1p2\n",
    "    loss += abs(a)\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = minimize(loss_merge_1and2, temp_price,\n",
    "                  tol=1e-5, method='Nelder-Mead')\n",
    "\n",
    "price_merge12 = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f875d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: Optimization terminated successfully.\n",
       "       success: True\n",
       "        status: 0\n",
       "           fun: 0.04195059299224147\n",
       "             x: [ 2.623e+00  1.452e+00  9.060e-01  1.491e+00  5.368e+00\n",
       "                  3.473e+00  9.359e+00  3.951e+00  2.749e+00  1.728e+00]\n",
       "           nit: 315\n",
       "          nfev: 533\n",
       " final_simplex: (array([[ 2.623e+00,  1.452e+00, ...,  2.749e+00,\n",
       "                         1.728e+00],\n",
       "                       [ 2.623e+00,  1.452e+00, ...,  2.749e+00,\n",
       "                         1.728e+00],\n",
       "                       ...,\n",
       "                       [ 2.623e+00,  1.452e+00, ...,  2.749e+00,\n",
       "                         1.728e+00],\n",
       "                       [ 2.623e+00,  1.452e+00, ...,  2.749e+00,\n",
       "                         1.728e+00]]), array([ 4.195e-02,  4.195e-02,  4.195e-02,  4.195e-02,\n",
       "                        4.195e-02,  4.195e-02,  4.195e-02,  4.195e-02,\n",
       "                        4.195e-02,  4.195e-02,  4.195e-02]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407221d7",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[3(d): when all firms are colluding](#toc0_)\n",
    "Clearly I can directly maximize profit (3(d)-1). Which is easy\n",
    "\n",
    "Alternatively I can also solve FOCs (3(d)-2).\n",
    "Now foc for each firm i is just\n",
    "$$s_j+\\sum_{k}\\partial s_k/\\partial p_j (p_k-c_k)=0$$\n",
    "Unluckily I didn't find a good solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d4be5",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_1_'></a>[3(d)-1: Direct maximize profit](#toc0_)\n",
    "\n",
    "There are two ways to maximize profit. \n",
    "- maximize total profit. So I define function loss_total_profit to minimize\n",
    "- solve GMM for 10 FOC\n",
    "\n",
    "Both methods are sensitive to their initial guess. So the basic idea is to go through a larger scale of initial guess and find the optimal initial guess for second round of maximization. \n",
    "\n",
    "I will also swicth these two methods: use the result as the other one's initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5c7e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: Optimization terminated successfully.\n",
       "       success: True\n",
       "        status: 0\n",
       "           fun: -13.74390226052609\n",
       "             x: [ 4.790e+01  6.613e+01  4.403e+01  4.436e+01  1.835e+01\n",
       "                  5.735e+01  2.073e+01  4.581e+01  4.391e+01  5.221e+01]\n",
       "           nit: 388\n",
       "          nfev: 612\n",
       " final_simplex: (array([[ 4.790e+01,  6.613e+01, ...,  4.391e+01,\n",
       "                         5.221e+01],\n",
       "                       [ 4.790e+01,  6.613e+01, ...,  4.391e+01,\n",
       "                         5.221e+01],\n",
       "                       ...,\n",
       "                       [ 4.789e+01,  6.613e+01, ...,  4.391e+01,\n",
       "                         5.221e+01],\n",
       "                       [ 4.789e+01,  6.613e+01, ...,  4.391e+01,\n",
       "                         5.221e+01]]), array([-1.374e+01, -1.374e+01, -1.374e+01, -1.374e+01,\n",
       "                       -1.374e+01, -1.374e+01, -1.374e+01, -1.374e+01,\n",
       "                       -1.374e+01, -1.374e+01, -1.374e+01]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# the total profit function given price\n",
    "def calc_profit_nest(temp_price):\n",
    "    [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(temp_price)\n",
    "    loss = 0\n",
    "    s_list = share_function_NestLogit(temp_price)\n",
    "    pi = [0]\n",
    "    for j in range(1, 11):\n",
    "        # need to control a non neg price. Otherwise would get -100+ price\n",
    "        if temp_price[j-1] <= 0:\n",
    "            pi.append(-100000)\n",
    "        else:\n",
    "            pi.append((temp_price[j-1]-c_j_dic1[(j, Temp_t)])\n",
    "                      * (s_j_dic1[(j, Temp_t)]))\n",
    "    return pi\n",
    "\n",
    "# find a price to maximize profit\n",
    "def loss_total_profit(p):\n",
    "    return -1 * np.sum(calc_profit_nest(p))\n",
    "\n",
    "# the loss for abs(diff:FOC) under full collusion\n",
    "# however this method is not easy\n",
    "def loss_merge_full_foc(price):\n",
    "    [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(price)\n",
    "    loss = 0\n",
    "    for j in range(1, 11):\n",
    "        s_j = s_j_dic1[(j, Temp_t)]\n",
    "        loss_j = s_j\n",
    "        for k in range(1, 11):\n",
    "            dskpj = d_sj_pk(k, j, price)\n",
    "            p_k = price[k-1]\n",
    "            c_k = c_j_dic1[(k, Temp_t)]\n",
    "            loss_j += dskpj*(p_k-c_k)\n",
    "\n",
    "        loss += abs(loss_j)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# I directly search for optimal p vector that maximizes the total profit. It gives an almost perfect answer\n",
    "# I first get c_j_dic, then for 10-merge, the initial guess is cost, so starting from profit 0\n",
    "random_price = list(data[data['t'] == 80]['price'])\n",
    "[c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(random_price)\n",
    "\n",
    "\n",
    "# fix inistail_guess_2. I will randomly shuffle initial_guess_2, and get a list of 10 prices, and then use it as initial guess. \n",
    "for increase_amt in range(0, 50, 10):\n",
    "    initial_guess_2 = [x+increase_amt for x in price_full_competition]\n",
    "    optimal_func = 0\n",
    "    optimal_price = 0\n",
    "    optimal_result = 0\n",
    "    for i in range(2):\n",
    "        random.shuffle(initial_guess_2)\n",
    "        result = minimize(loss_total_profit, initial_guess_2,\n",
    "                          tol=1e-2, method='Nelder-Mead')\n",
    "        if result.fun < optimal_func:\n",
    "            optimal_func = result.fun\n",
    "            optimal_price = result.x\n",
    "            optimal_result = result\n",
    "\n",
    "optimal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd73d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 firm total market share== 0.78\n"
     ]
    }
   ],
   "source": [
    "# that's the total demand of the market. Should get a little number, when prices are high: use to check share function. Makes sense to me.\n",
    "def total_share(price):\n",
    "    return np.sum(share_function_NestLogit(price))\n",
    "\n",
    "print('10 firm total market share==',round(total_share(optimal_price),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10806c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 0.49928582164011565), (5, 0.27753930727470266)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_function_NestLogit(optimal_price)  # firm 5 has 27%, firm 7 has 49%\n",
    "\n",
    "def who_has_large_share(price):\n",
    "    # return the firm with largest shares, within those whose share is larger than 0.001\n",
    "    share_lis = share_function_NestLogit(price)\n",
    "    threshold = 0.001\n",
    "    dic=dict()\n",
    "    for i in range(10):\n",
    "        dic[i+1]=share_lis[i]\n",
    "    sorted_dic = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "    wanted_list=[]\n",
    "    for i in range(10):\n",
    "        if sorted_dic[i][1]>threshold:\n",
    "            wanted_list.append(sorted_dic[i])\n",
    "    return wanted_list\n",
    "\n",
    "who_has_large_share(optimal_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc4c250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2532813843353505"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0d0b9",
   "metadata": {},
   "source": [
    "## 3(a)-1,3(b),3(d).Comparison results: Intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_merge_full = optimal_price\n",
    "full_merge_share_lis = share_function_NestLogit(price_merge_full)\n",
    "# rank by ascending order of full_merge_share_lis and return the index\n",
    "def rank_full_merge_share_lis(full_merge_share_lis):\n",
    "    ans = np.argsort(full_merge_share_lis)\n",
    "    ans = [x+1 for x in ans] # since index starts from 0\n",
    "    # reverse the list\n",
    "    return ans[::-1]\n",
    "\n",
    "rank_full_merge_share_lis(full_merge_share_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec32b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's the rank of t100 market's xi_jt. So 5 and 7 are stars in each nest\n",
    "list(data[['product_ID', 'market_share', 'xi_hat', 'Lerner_nest','t']].query('t==100').sort_values('xi_hat',ascending=False)['product_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d586577",
   "metadata": {},
   "outputs": [],
   "source": [
    "paint(price_full_competition, price_merge12, price_merge_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_total_1 = np.sum(calc_profit_nest(price_full_competition))\n",
    "profit_total_1\n",
    "\n",
    "profit_total_3= np.sum(calc_profit_nest(price_merge_full))\n",
    "profit_total_3/profit_total_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd6f25",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_2_'></a>[3(d)-2 use FOC to solve Nash](#toc0_)\n",
    "\n",
    "didn't get good answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss for abs(diff:FOC) under full collusion\n",
    "# however this method is not easy\n",
    "def loss_merge_full(price):\n",
    "    [c_j_dic1, s_j_dic1, s_g_dic1, s_jmidg_dic1] = other_items(price)\n",
    "    loss = 0\n",
    "    for j in range(1, 11):\n",
    "        s_j = s_j_dic1[(j, Temp_t)]\n",
    "        loss_j = s_j\n",
    "        for k in range(1, 11):\n",
    "            dskpj = d_sj_pk(k, j, price)\n",
    "            p_k = price[k-1]\n",
    "            c_k = c_j_dic1[(k, Temp_t)]\n",
    "            loss_j += dskpj*(p_k-c_k)\n",
    "\n",
    "        loss += abs(loss_j)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = minimize(loss_merge_full, price_merge_full_initial_guess_clever,\n",
    "                  tol=1e-3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e115bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a3102e4",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[4: redo 3 with MultiNomial Logit](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f43c",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[3(a)](#toc0_)\n",
    "I still use MNL demand for this part, since outcomes for NestLogit seems weird. \n",
    "\n",
    "The FOC is $s_{jt}+(P_{jt}-c_{jt})\\frac{\\partial s_{jt}}{\\partial p_{jt}}=0$\n",
    "\n",
    "If we believe the market data represents the Nash Equilibrium status, then mutual best response means $\\frac{\\partial s_{jt}}{\\partial p_{jt}}$ is evaluated when $s_{-j,t}$ lies in the EQM level: the point estimate we get is also a function evaluated at EQM.\n",
    "\n",
    "\n",
    "so we can estimate $\\hat c_jt=P_{jt}+s_{jt}/(\\frac{\\partial s_{jt}}{\\partial p_{jt}})$\n",
    "\n",
    "\n",
    "\n",
    "The can query by own_price_derivative(alpha, s_jt), but actually is stored in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92593c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7569f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost_Lerner(data):\n",
    "    data['middle'] = data['market_share']/data['own_price_derivative']\n",
    "    data['cost'] = data['price']+data['middle']\n",
    "    data['middle_2'] = data['price']-data['cost']\n",
    "    data['Lerner'] = data['middle_2']/data['price']\n",
    "    data = data.drop('middle', axis=1).drop('middle_2', axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "data = calc_cost_Lerner(data)\n",
    "# seems that MNL under estimates the cost\n",
    "data.groupby('product_ID').agg({'Lerner': np.mean, 'Lerner_nest': np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e6a1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these global varibles for estimating MNL demand\n",
    "c_jt_dic = dict(data.set_index(['product_ID', 't'])['cost'])\n",
    "[alpha, beta1, beta2, gammaD, gammaR] = params_IV.values()\n",
    "RHS_Var = ['price', 'sugar', 'caffeine', 'Diet', 'Regular', 't']\n",
    "demand_df = data[RHS_Var]\n",
    "\n",
    "# set these global v for solve_NE()\n",
    "PARAMS = list(params_IV.values())\n",
    "Temp_t = 100\n",
    "alpha = PARAMS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0103a",
   "metadata": {},
   "source": [
    "For EQM we have $p_{jt}=c_{jt}-\\frac{s_{jt}}{\\partial s_{jt}/\\partial p_{jt}}$ which is\n",
    "$p_{jt}=c_{jt}-\\frac{1}{\\alpha(1-s_{jt})}$. So I'm looking for a 10-dim vector $p_t$ which solves (or equivalently minimizes the norm of diff):\n",
    "$$\n",
    "1/(c_{jt}-p_{jt})=\\alpha (1-s_{jt}(p))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039d8f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9ef67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### For Nash Solver Part###############\n",
    "# a function for demand/share under MNL setting\n",
    "def share_function_MNL(temp_price):\n",
    "    global demand_df, c_jt_dic, PARAMS, alpha, Temp_t, data\n",
    "    \"\"\"This is a mapping: given params&demand_df(I need sugar,caffeine, Diet,Regular),\n",
    "    period t, and len-10 vector price, generate expected market share which is also len-10 vector\"\"\"\n",
    "    [alpha, beta1, beta2, gammaD, gammaR] = PARAMS\n",
    "    temp_t = Temp_t\n",
    "    temp_demand_df = demand_df[demand_df['t'] == temp_t]\n",
    "    temp_demand_df['M'] = temp_demand_df['sugar']*beta1+temp_demand_df['caffeine'] * \\\n",
    "        beta2+temp_demand_df['Diet']*gammaD+temp_demand_df['Regular']*gammaR\n",
    "    temp_demand_df['exp_M'] = np.exp(temp_demand_df['M'])\n",
    "    temp_demand_df['Price'] = temp_price\n",
    "    temp_demand_df['middle'] = temp_demand_df['Price']*alpha\n",
    "    temp_demand_df['exp_P'] = np.exp(temp_demand_df['middle'])\n",
    "    temp_demand_df['exp_delta'] = temp_demand_df['exp_M'] * \\\n",
    "        temp_demand_df['exp_P']\n",
    "    denom = temp_demand_df['exp_delta'].sum()+1  # +1 for outside option\n",
    "    temp_demand_df['expected_share'] = temp_demand_df['exp_delta']/denom\n",
    "\n",
    "    temp_demand_df = temp_demand_df.sort_index()\n",
    "    # to make sure the sort is correct so I can check j's expected share by [j-1]\n",
    "    return list(temp_demand_df['expected_share'])\n",
    "\n",
    "\n",
    "# The kernal to solve Nash. Notice that under nest setting all FOC will look totally different since derivatives are more complex. SO I give up writing them in one function. Instead I will define another solve_Nash_Nest\n",
    "def solve_Nash(initial_guess, question=1, share_function=share_function_MNL):\n",
    "    \"\"\"Solve NE by minimizing norm of 10 equations. Return a 10-dim vector of prices\"\"\"\n",
    "    global demand_df, c_jt_dic, PARAMS, alpha, Temp_t, data\n",
    "    # a loss function for each j,t: given p, tell loss from j\n",
    "\n",
    "    def loss(p_vec, j, s_list):\n",
    "        p_j = p_vec[j-1]\n",
    "        c_jt = c_jt_dic[(j, Temp_t)]  # check the cost\n",
    "        LHS = 1/(c_jt-p_j)\n",
    "        s_jt = s_list[j-1]  # the estimated market share under p_vec\n",
    "        RHS = alpha*(1-s_jt)\n",
    "        return abs(LHS-RHS)\n",
    "        return (LHS-RHS)*(LHS-RHS)\n",
    "\n",
    "    # another loss specifically for 3(b):merging between 1 and 2\n",
    "    def loss_q3b(p_vec, s_list):\n",
    "        p_1 = p_vec[0]\n",
    "        p_2 = p_vec[1]\n",
    "\n",
    "        c_1 = c_jt_dic[(1, Temp_t)]  # check the cost\n",
    "        c_2 = c_jt_dic[(2, Temp_t)]  # check the cost\n",
    "\n",
    "        s_1 = s_list[0]  # the estimated market share under p_vec\n",
    "        s_2 = s_list[1]\n",
    "\n",
    "        def diff(p1, c1, s1, p2, c2, s2):\n",
    "            lhs = 1+(p1-c1)*alpha*(1-s1)\n",
    "            rhs = (p2-c2)*alpha*s2\n",
    "            return abs(lhs-rhs)\n",
    "\n",
    "        return diff(p_1, c_1, s_1, p_2, c_2, s_2)+diff(p_2, c_2, s_2, p_1, c_1, s_1)\n",
    "\n",
    "    # a Loss function: given p, tell loss from 10 firms\n",
    "\n",
    "    def LOSS_Q_1(p_vec):\n",
    "        s_list = share_function(p_vec)\n",
    "        sum1 = 0\n",
    "        for j in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            sum1 += loss(p_vec, j, s_list)\n",
    "        return sum1\n",
    "\n",
    "    def LOSS_Q_2(p_vec):\n",
    "        s_list = share_function(p_vec)\n",
    "        sum1 = 0\n",
    "        for j in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            sum1 += loss(p_vec, j, s_list)\n",
    "        sum1 += loss_q3b(p_vec, s_list)\n",
    "        return sum1\n",
    "\n",
    "    def LOSS_Q_3(p_vec):\n",
    "        s_list = share_function(p_vec)\n",
    "        p = p_vec\n",
    "        sum1 = 0\n",
    "        for j in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            lhs = 1+(p[j-1]-c_jt_dic[(j, Temp_t)])*alpha*(1-s_list[j-1])\n",
    "            rhs = 0\n",
    "            for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "                if k != j:\n",
    "                    rhs += (p[k-1]-c_jt_dic[(k, Temp_t)])*alpha*(s_list[k-1])\n",
    "            sum1 += (lhs-rhs)**2\n",
    "        return sum1\n",
    "\n",
    "    if question == 1:\n",
    "        result = minimize(LOSS_Q_1, initial_guess,\n",
    "                          tol=1e-5, method='Nelder-Mead')\n",
    "    elif question == 2:\n",
    "        result = minimize(LOSS_Q_2, initial_guess,\n",
    "                          tol=1e-5, method='Nelder-Mead')\n",
    "    elif question == 3:\n",
    "        result = minimize(LOSS_Q_3, initial_guess,\n",
    "                          tol=1e-8, method='Nelder-Mead')\n",
    "\n",
    "    print('number of iterations for minimize kernal:', result.nit)\n",
    "    price_star = result.x\n",
    "    return price_star, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1ee8c",
   "metadata": {},
   "source": [
    "The following results show that my solution kernal is sensitive to the initial guess. Sometimes it's even negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_star, result = solve_Nash(\n",
    "    initial_guess=list(data[data['t'] == 79]['price']))\n",
    "price_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ee2b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1221d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_star, result = solve_Nash(\n",
    "    initial_guess=list(data[data['t'] == 100]['price']))\n",
    "price_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50de86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_star, result = solve_Nash(initial_guess=list(\n",
    "    data[data['t'] == 100]['price']), share_function=share_function_NestLogit)\n",
    "price_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42474826",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[3(b)](#toc0_)\n",
    "Now firm 1 and 2 are collusion, then firm 3-10 has the same FOC as we did before, but 1 and 2 will change their decision to $\\max_{p_1,p_2} (p_1-c_1)s_1(p_1,p_2,p_o)+(p_2-c_2)s_2(p_1,p_2,p_o)$, where $p_o$ stands for other firm's decision. Then their FOC will switch to:\n",
    "$$1+(p_1-c_1) \\alpha(1-s_1) = (p_2-c_2)\\alpha s_2$$\n",
    "and \n",
    "$$1+(p_2-c_2) \\alpha(1-s_2) = (p_1-c_1)\\alpha s_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_star_q2, result_q2 = solve_Nash(initial_guess=list(\n",
    "    data[data['t'] == 100]['price']), question=2)\n",
    "price_star_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba12f1",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[3(c) and 3(d)](#toc0_)\n",
    "I put them together for simplicity.\n",
    "\n",
    "Now if ten of them merge, the every price is set to maximize total profit. FOC will switch to \n",
    "$$1+(p_i-c_i)\\alpha (1-s_i)=\\sum_{k\\neq i}\\alpha(p_k-c_k)s_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: Directly solve FOC by GMM, starting from a dummy initial guess will give really wrong answer. In this price, the collusion profit is 30% of total profit get in independent case. However later works show it's solely because of the solver doesn't give correct minimizer. If I start from a clever initial guess than I will get the correct answer.\n",
    "price_star_q3, result_q3 = solve_Nash(initial_guess=list(\n",
    "    data[data['t'] == 100]['price']), question=3)\n",
    "price_star_q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891cd5f",
   "metadata": {},
   "source": [
    "It make sense that the collusion between 1 and 2 won't change their pricing a lot, since their market share is really small (6%). 2 is extremely small (2% of the market share of 1), so one should expect there is no much change for 1's pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c208fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_share_list100 = list(data[data['t'] == 100]['market_share'])\n",
    "market_share_list100[0] + \\\n",
    "    market_share_list100[1], market_share_list100[1]/market_share_list100[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_profit(temp_price):\n",
    "    s_list = share_function_MNL(temp_price)\n",
    "    pi = [0]\n",
    "    for j in range(1, 11):\n",
    "        # print(j,temp_price[j-1],c_jt_dic[(j,Temp_t)],s_list[j-1])\n",
    "        pi.append((temp_price[j-1]-c_jt_dic[(j, Temp_t)])*(s_list[j-1]))\n",
    "    return pi\n",
    "\n",
    "\n",
    "def loss_total_profit(p):\n",
    "    return -1 * np.sum(calc_profit(p))\n",
    "\n",
    "\n",
    "# step 2: I directly search for optimal p vector that maximizes the total profit. It gives an almost perfect answer, but since the tolerance is quite high, I just use it as a clever initial guess for Nash solver (GMM).\n",
    "initial_guess = list(data[data['t'] == 100]['price'])\n",
    "result = minimize(loss_total_profit, initial_guess,\n",
    "                  tol=1e-3, method='Nelder-Mead')\n",
    "# here if set tol =1e-4 then it performs quite well. Then no place for my Nash Solver, not cool.\n",
    "paint(price_star, price_star_q2, result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Use theory_optimal_price as an initial guess for GMM solver. Finally I get price_star_q3_prime which is even better than theory_xx.\n",
    "optimal_profit = np.sum(calc_profit(result.x))\n",
    "global theory_optimal_price\n",
    "theory_optimal_price = result.x\n",
    "\n",
    "price_star_q3_prime, result_q3_prime = solve_Nash(\n",
    "    initial_guess=theory_optimal_price, question=3)\n",
    "paint(price_star, price_star_q2, price_star_q3_prime)\n",
    "# and the optimal price_star for 10-collusion is price_star_q3_prime\n",
    "print(price_star_q3_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_q1 = calc_profit(price_star)\n",
    "pi_q2 = calc_profit(price_star_q2)\n",
    "pi_q3 = calc_profit(price_star_q3_prime)\n",
    "pi_q3_prime = calc_profit(price_star_q3_prime)\n",
    "judge_q2profitable = pi_q1[1]+pi_q1[2] <= pi_q2[1]+pi_q2[2]\n",
    "judge_q3profitable = np.sum(pi_q1) <= np.sum(pi_q3)\n",
    "\n",
    "print(judge_q2profitable, (pi_q2[1]+pi_q2[2])/pi_q1[1]+pi_q1[2])\n",
    "print(judge_q3profitable, np.sum(pi_q3)/np.sum(pi_q1))\n",
    "# So my results say :\n",
    "# If 1 and 2 collude then both firm's profit increases by 20%\n",
    "# If all firms collude then the total profit increases by 237%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7599a2",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_1_'></a>[Answer for 3(c):](#toc0_)\n",
    "After the merging of 1 and 2, prices generally increases a little bit since there is less competition. Firm 2 increases the most, since its share is very small compared to 1.\n",
    "\n",
    "The increase in the same nest is larger, since the drop of competition is larger within the same nest. Also it's because the original price is generally lower in Diet nest.\n",
    "\n",
    "Competing products from different nests also increase their price, but with lower rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_compare = {}\n",
    "dic_compare['Competetion'] = price_star\n",
    "dic_compare['Merging 1_2'] = price_star_q2\n",
    "dic_compare['Merging 10'] = price_star_q3_prime\n",
    "df = pd.DataFrame(dic_compare)\n",
    "df['case2/case1:Increase By Percent'] = (\n",
    "    df['Merging 1_2']/df['Competetion']-1)*100\n",
    "df['case3/case1:Increase By Percent'] = (\n",
    "    df['Merging 10']/df['Competetion']-1)*100\n",
    "df.index = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "group = data[data['t'] == 1][['product_ID', 'nest']].set_index('product_ID')\n",
    "df['nest'] = group['nest']\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be861ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('nest').agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b7776",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bdec6c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
